{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the packages and the combined data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "#!conda install py-xgboost --y\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from random import choices\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost \n",
    "\n",
    "#from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# No warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('DF.csv')\n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features of interest based on the preliminary analysis from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.loc[:,[ 'WEATHER_CONDITION',\n",
    "       'CRASH_DAY_OF_WEEK', 'CRASH_MONTH', 'CRASH_HOUR', 'LIGHTING_CONDITION',\n",
    "       'MANEUVER', 'TRAFFICWAY_TYPE', 'PRIM_CONTRIBUTORY_CAUSE',\n",
    "       'POSTED_SPEED_LIMIT','COMBINED_DANGER_SCORE']]\n",
    "\n",
    "df.head()\n",
    "df_test_interest = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used four different techniques to address the issue of imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 93876, 2.0: 111759, 3.0: 20533}\n"
     ]
    }
   ],
   "source": [
    "# Approach 1: Upsampling or known as oversampling\n",
    "\n",
    "## do RANDOM SAMPLING TO PICK EQUAL NUMBER OF DATA IN EACH Y GROUP\n",
    "# down sampling\n",
    "df4=df.reset_index()\n",
    "X=df4.drop(columns = 'COMBINED_DANGER_SCORE')\n",
    "y=df4.COMBINED_DANGER_SCORE\n",
    "\n",
    "# find the number of levels in y and number of entries associated with each level\n",
    "\n",
    "unique_levels = np.unique(y)\n",
    "unique_counts = {level: sum(y == level) for level in unique_levels}\n",
    "print(unique_counts)\n",
    "\n",
    "# find the target number of data points\n",
    "unique_counts.items()\n",
    "max_level = max(unique_counts.items(), key=operator.itemgetter(1))[0]\n",
    "min_level = min(unique_counts.items(), key=operator.itemgetter(1))[0]\n",
    "target_number = unique_counts[max_level]\n",
    "target_number_min = unique_counts[min_level]\n",
    "\n",
    "# find which data points are associated with which group\n",
    "\n",
    "grouped_levels = {}\n",
    "for ii, level in enumerate(unique_levels):\n",
    "    obs_idx = [idx for idx, val in enumerate(y) if val == level]\n",
    "    grouped_levels[level] = obs_idx\n",
    "\n",
    "grouped_levels\n",
    "\n",
    "#oversampling\n",
    "sampled_levels={}\n",
    "\n",
    "# sample indices\n",
    "for i in list(unique_levels):\n",
    "    if i != max_level:\n",
    "        sampled_levels[i] = choices(grouped_levels[i], k=target_number )\n",
    "    else:\n",
    "        sampled_levels[i] = grouped_levels[i]\n",
    "\n",
    "first = df4.iloc[sampled_levels[1]].reset_index()\n",
    "second = df4.iloc[sampled_levels[2]].reset_index()\n",
    "third = df4.iloc[sampled_levels[3]].reset_index()\n",
    "\n",
    "new_oversampled = pd.concat([first,second,third], axis = 0)\n",
    "new_oversampled = new_oversampled.drop(columns = ['level_0','index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2: Downsampling \n",
    "\n",
    "sampled_levels={}\n",
    "\n",
    "# sample indices\n",
    "for i in list(unique_levels):\n",
    "    if i != min_level:\n",
    "        sampled_levels[i] = choices(grouped_levels[i], k=target_number_min )\n",
    "    else:\n",
    "        sampled_levels[i] = grouped_levels[i]\n",
    "\n",
    "first = df4.iloc[sampled_levels[1]].reset_index()\n",
    "second = df4.iloc[sampled_levels[2]].reset_index()\n",
    "third = df4.iloc[sampled_levels[3]].reset_index()\n",
    "\n",
    "new_downsampled = pd.concat([first,second,third], axis = 0)\n",
    "new_downsampled = new_downsampled.drop(columns = ['level_0','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_interest = new_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to convert categorical variables to categories for one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEATHER_CONDITION           int64\n",
      "CRASH_DAY_OF_WEEK           int64\n",
      "LIGHTING_CONDITION          int64\n",
      "MANEUVER                   object\n",
      "TRAFFICWAY_TYPE            object\n",
      "PRIM_CONTRIBUTORY_CAUSE    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "labels = ['WEATHER_CONDITION', 'CRASH_DAY_OF_WEEK','LIGHTING_CONDITION','MANEUVER', 'TRAFFICWAY_TYPE', 'PRIM_CONTRIBUTORY_CAUSE']\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "print(df_train_interest[labels].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_interest = pd.get_dummies(df_train_interest, drop_first = True)\n",
    "df_test_interest = pd.get_dummies(df_test_interest, drop_first = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into test and training datasets. While testing, remember to use the real data to obtain a more realistic result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33662731573595084\n",
      "[0.46721094 0.16117249 0.67683508]\n",
      "[0.50576758 0.52558824 0.13518016]\n",
      "0.5053720652606446\n",
      "[0.50553995 0.44387824 0.82959962]\n",
      "[0.58740914 0.64015349 0.25550499]\n",
      "0.3369368174382102\n",
      "[0.4317977  0.18620068 0.707102  ]\n",
      "[0.52241678 0.52901986 0.13586409]\n"
     ]
    }
   ],
   "source": [
    "# machine learning algorithm\n",
    "accuracy_list_log=[]\n",
    "recall_list_log = []\n",
    "precision_list_log = []\n",
    "\n",
    "accuracy_list_forest=[]\n",
    "recall_list_forest = []\n",
    "precision_list_forest = []\n",
    "\n",
    "accuracy_list_boost=[]\n",
    "recall_list_boost = []\n",
    "precision_list_boost = []\n",
    "\n",
    "\n",
    "for i in range(0,20):\n",
    "    train_df1, test_df1 = train_test_split(df_train_interest, test_size=0.2)\n",
    "    train_df2, test_df2 = train_test_split(df_test_interest, test_size=0.2)\n",
    "\n",
    "    X_train = train_df1.drop(columns = 'COMBINED_DANGER_SCORE')\n",
    "    Y_train = train_df1.COMBINED_DANGER_SCORE\n",
    "    X_test  = test_df2.drop(columns = 'COMBINED_DANGER_SCORE')\n",
    "    Y_test = test_df2.COMBINED_DANGER_SCORE\n",
    "    \n",
    "    LogisticRegressionModel = linear_model.LogisticRegression()\n",
    "\n",
    "    LogisticRegressionModel.fit(X_train,Y_train)\n",
    "    accuracy = LogisticRegressionModel.score(X_test,Y_test)\n",
    "    accuracy_list_log.append(accuracy)\n",
    "    #print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "    Y_true = Y_test\n",
    "    Y_pred = LogisticRegressionModel.predict(X_test)\n",
    "    ConfusionMatrix = pd.DataFrame(confusion_matrix(Y_true,Y_pred), columns = ['Predicted 1', 'Predicted 2','Predicted 3'], index = ['Actual 1', 'Actual 2','Actual 3'])\n",
    "    #print ('Confusion matrix of test data is: \\n',ConfusionMatrix)\n",
    "    \n",
    "    recall = recall_score(Y_true, Y_pred, average = None)\n",
    "    recall_list_log.append(np.array(recall))\n",
    "    #print(\"Average recall for the 3 classes is - \", recall)\n",
    "    \n",
    "    precision = precision_score(Y_true, Y_pred, average = None)\n",
    "    precision_list_log.append(np.array(precision))\n",
    "    #print(\"Average precision for the 3 classes is - \", precision)\n",
    "\n",
    "    # random forest\n",
    "    classifier = RandomForestClassifier(n_estimators = 30, criterion = 'entropy')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    Y_pred_forest = classifier.predict(X_test)\n",
    "    Y_true_forest = Y_test\n",
    "\n",
    "    accuracy = classifier.score(X_test,Y_test)\n",
    "    accuracy_list_forest.append(accuracy)\n",
    "\n",
    "    ConfusionMatrix = pd.DataFrame(confusion_matrix(Y_true_forest,Y_pred_forest), columns = ['Predicted 1', 'Predicted 2','Predicted 3'], index = ['Actual 1', 'Actual 2','Actual 3'])\n",
    "    #print ('Confusion matrix of test data is: \\n',ConfusionMatrix)\n",
    "    #print(\"Average recall for the 3 classes is - \", recall_score(Y_true_forest, Y_pred_forest, average = None))\n",
    "    #print(\"Average precision for the 3 classes is - \", precision_score(Y_true_forest, Y_pred_forest, average = None))\n",
    "    \n",
    "    recall = recall_score(Y_true_forest, Y_pred_forest, average = None)\n",
    "    recall_list_forest.append(np.array(recall))\n",
    "    #print(\"Average recall for the 3 classes is - \", recall)\n",
    "    \n",
    "    precision = precision_score(Y_true_forest, Y_pred_forest, average = None)\n",
    "    precision_list_forest.append(np.array(precision))\n",
    "    \n",
    "      #xgboost\n",
    "    import os\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # evaluate predictions\n",
    "    boost_accuracy = accuracy_score(Y_test, predictions)\n",
    "    accuracy_list_boost.append(boost_accuracy)\n",
    "    #print(\"Accuracy: %.2f%%\" % (accuracy * 100.0)) \n",
    "\n",
    "    boost_confusionMatrix = pd.DataFrame(confusion_matrix(Y_true,Y_pred), columns = ['Predicted 1', 'Predicted 2','Predicted 3'], index = ['Actual 1', 'Actual 2','Actual 3'])\n",
    "    #print ('Confusion matrix of test data using random forest is: \\n',boost_confusionMatrix )\n",
    "    \n",
    "    recall = recall_score(Y_true, Y_pred, average = None)\n",
    "    recall_list_boost.append(np.array(recall))\n",
    "    precision = precision_score(Y_true, Y_pred, average = None)\n",
    "    precision_list_boost.append(np.array(precision))\n",
    "\n",
    "print(np.mean(accuracy_list_log))\n",
    "print(np.mean(recall_list_log, axis = 0))\n",
    "print(np.mean(precision_list_log, axis = 0))\n",
    "\n",
    "\n",
    "print(np.mean(accuracy_list_forest))\n",
    "print(np.mean(recall_list_forest, axis = 0))\n",
    "print(np.mean(precision_list_forest, axis = 0))\n",
    "\n",
    "print(np.mean(accuracy_list_boost))\n",
    "print(np.mean(recall_list_boost, axis = 0))\n",
    "print(np.mean(precision_list_boost, axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Approach 3: SMOTE\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "labels = ['WEATHER_CONDITION', 'CRASH_DAY_OF_WEEK','LIGHTING_CONDITION','MANEUVER', 'TRAFFICWAY_TYPE', 'PRIM_CONTRIBUTORY_CAUSE']\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[labels] = df[labels].astype('category')\n",
    "df = pd.get_dummies(df, drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33806428792501214\n",
      "[0.45988791 0.17775793 0.65612071]\n",
      "[0.50262513 0.53017184 0.13096915]\n",
      "0.5430870584073927\n",
      "[0.53738991 0.61067441 0.20077878]\n",
      "[0.52568922 0.57672516 0.34751474]\n",
      "0.5259539284608923\n",
      "[0.34763811 0.77168379 0.        ]\n",
      "[0.53724326 0.5218363  0.        ]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_log=[]\n",
    "recall_list_log = []\n",
    "precision_list_log = []\n",
    "\n",
    "accuracy_list_forest=[]\n",
    "recall_list_forest = []\n",
    "precision_list_forest = []\n",
    "\n",
    "accuracy_list_boost=[]\n",
    "recall_list_boost = []\n",
    "precision_list_boost = []\n",
    "\n",
    "for i in range(0,20):\n",
    "    train_df1, test_df1 = train_test_split(df, test_size=0.2)\n",
    "    X_train_SMOTE = train_df1.drop(columns = 'COMBINED_DANGER_SCORE')\n",
    "    Y_train_SMOTE = train_df1.COMBINED_DANGER_SCORE\n",
    "    X_test_SMOTE = test_df1.drop(columns = 'COMBINED_DANGER_SCORE')\n",
    "    Y_test_SMOTE = test_df1.COMBINED_DANGER_SCORE\n",
    "\n",
    "    X_resampled_SMOTE, Y_resampled_SMOTE = SMOTE().fit_sample(X_train_SMOTE, Y_train_SMOTE)\n",
    "    #print(sorted(Counter(Y_resampled_SMOTE).items()))\n",
    "\n",
    "    LogisticRegressionModel.fit(X_resampled_SMOTE,Y_resampled_SMOTE)\n",
    "    log_accuracy = LogisticRegressionModel.score(X_test_SMOTE,Y_test_SMOTE)\n",
    "    accuracy_list_log.append(log_accuracy)\n",
    "    #print(\"Logistic accuracy: %.2f%%\" % (log_accuracy * 100.0))\n",
    "\n",
    "    Y_true_SMOTE = Y_test_SMOTE\n",
    "    Y_pred_SMOTE = LogisticRegressionModel.predict(X_test_SMOTE)\n",
    "    Log_ConfusionMatrix = pd.DataFrame(confusion_matrix(Y_true_SMOTE,Y_pred_SMOTE), columns = ['Predicted 1', 'Predicted 2','Predicted 3'], index = ['Actual 1', 'Actual 2','Actual 3'])\n",
    "    #print ('Confusion matrix of test data using Logistic regression is: \\n',Log_ConfusionMatrix)\n",
    "\n",
    "    recall = recall_score(Y_true_SMOTE, Y_pred_SMOTE, average = None)\n",
    "    recall_list_log.append(np.array(recall))\n",
    "    precision = precision_score(Y_true_SMOTE, Y_pred_SMOTE, average = None)\n",
    "    precision_list_log.append(np.array(precision))\n",
    "    \n",
    "    #print(\"Average recall for the 3 classes using Logistic regression  is - \", recall_score(Y_true_SMOTE,Y_pred_SMOTE, average = None))\n",
    "    #print(\"Average precision for the 3 classes using Logistic regression is - \", precision_score(Y_true_SMOTE,Y_pred_SMOTE, average = None))\n",
    "\n",
    "    # random forest\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "    classifier.fit(X_train_SMOTE, Y_train_SMOTE)\n",
    "    Y_pred_SMOTE_forest = classifier.predict(X_test_SMOTE)\n",
    "    Y_true_SMOTE_forest = Y_test_SMOTE\n",
    "\n",
    "\n",
    "    forest_accuracy = classifier.score(X_test_SMOTE,Y_test_SMOTE)\n",
    "    accuracy_list_forest.append(forest_accuracy)\n",
    "    #print(\"Random Forest accuracy: %.2f%%\" % (forest_accuracy * 100.0))\n",
    "\n",
    "    forest_confusionMatrix = pd.DataFrame(confusion_matrix(Y_true_SMOTE_forest,Y_pred_SMOTE_forest), columns = ['Predicted 1', 'Predicted 2','Predicted 3'], index = ['Actual 1', 'Actual 2','Actual 3'])\n",
    "    #print ('Confusion matrix of test data using random forest is: \\n',forest_confusionMatrix )\n",
    "    recall = recall_score(Y_true_SMOTE_forest, Y_pred_SMOTE_forest, average = None)\n",
    "    recall_list_forest.append(np.array(recall))\n",
    "    #print(\"Average recall for the 3 classes is - \", recall)\n",
    "    \n",
    "    precision = precision_score(Y_true_SMOTE_forest, Y_pred_SMOTE_forest, average = None)\n",
    "    precision_list_forest.append(np.array(precision))\n",
    "    #print(\"Average recall for the 3 classes using Logistic regression  is - \", recall_score(Y_true_SMOTE_forest,Y_pred_SMOTE_forest, average = None))\n",
    "    #print(\"Average precision for the 3 classes using Logistic regression is - \", precision_score(Y_true_SMOTE_forest,Y_pred_SMOTE_forest, average = None))\n",
    "    \n",
    "    #xgboost\n",
    "    import os\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train_SMOTE, Y_train_SMOTE)\n",
    "\n",
    "    Y_pred = model.predict(X_test_SMOTE)\n",
    "    predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # evaluate predictions\n",
    "    boost_accuracy = accuracy_score(Y_test_SMOTE, predictions)\n",
    "    accuracy_list_boost.append(boost_accuracy)\n",
    "    #print(\"Accuracy: %.2f%%\" % (accuracy * 100.0)) \n",
    "\n",
    "    boost_confusionMatrix = pd.DataFrame(confusion_matrix(Y_true,Y_pred), columns = ['Predicted 1', 'Predicted 2','Predicted 3'], index = ['Actual 1', 'Actual 2','Actual 3'])\n",
    "    #print ('Confusion matrix of test data using random forest is: \\n',boost_confusionMatrix )\n",
    "    \n",
    "    recall = recall_score(Y_true_SMOTE, Y_pred, average = None)\n",
    "    recall_list_boost.append(np.array(recall))\n",
    "    precision = precision_score(Y_true_SMOTE, Y_pred, average = None)\n",
    "    precision_list_boost.append(np.array(precision))\n",
    "\n",
    "    \n",
    "print(np.mean(accuracy_list_log))\n",
    "print(np.mean(recall_list_log, axis = 0))\n",
    "print(np.mean(precision_list_log, axis = 0))\n",
    "\n",
    "print(np.mean(accuracy_list_forest))\n",
    "print(np.mean(recall_list_forest, axis = 0))\n",
    "print(np.mean(precision_list_forest, axis = 0))\n",
    "\n",
    "print(np.mean(accuracy_list_boost))\n",
    "print(np.mean(recall_list_boost, axis = 0))\n",
    "print(np.mean(precision_list_boost, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 4: ADASYN\n",
    "\n",
    "# sm = ADASYN()\n",
    "# X_resampled_ADASYN, Y_resampled_ADASYN = sm.fit_sample(X_train, Y_train)\n",
    "# print(sorted(Counter(Y_resampled_ADASYN).items()))\n",
    "\n",
    "\n",
    "# LogisticRegressionModel.fit(X_resampled_ADASYN,Y_resampled_ADASYN)\n",
    "# print(LogisticRegressionModel.score(X_test,Y_test))\n",
    "\n",
    "# Y_true = Y_test\n",
    "# Y_pred = LogisticRegressionModel.predict(X_test)\n",
    "# ConfusionMatrix = pd.DataFrame(confusion_matrix(Y_true,Y_pred), columns = ['Predicted 1', 'Predicted 2','Predicted 3'], index = ['Actual 1', 'Actual 2','Actual 3'])\n",
    "# ConfusionMatrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
